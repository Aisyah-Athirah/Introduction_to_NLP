{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Introduction to Natural Language Processing with Hugging Face Transformers**"
      ],
      "metadata": {
        "id": "voMC_xE35tt6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Installing Required Libraries**"
      ],
      "metadata": {
        "id": "X4t9RLqMma3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The following required libraries are pre-installed in the Skills Network Labs environment.\n",
        "# However, if you run this notebook commands in a different Jupyter environment (e.g. Watson Studio or Ananconda),\n",
        "# you will need to install these libraries by removing the # sign before !mamba in the code cell below."
      ],
      "metadata": {
        "id": "p9enzqiXnjFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All Libraries required for this lab are listed below. The libraries pre-installed on Skills Network Labs are commented.\n",
        "# !mamba install -qy pandas==1.3.4 numpy==1.21.4 seaborn==0.9.0 matplotlib==3.5.0 scikit-learn==0.20.1\n",
        "# Note: If your environment doesn't support \"!mamba install\", use \"!pip install\""
      ],
      "metadata": {
        "id": "Q2tTMNRKnVB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwoH7pr06Rjv",
        "outputId": "1bf0d0b5-c826-4378-9648-ab340aad72c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers"
      ],
      "metadata": {
        "id": "ZvACk0gf6RhO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pq6otEWY6ReQ",
        "outputId": "ff7e4045-5a68-4d22-b999-4545eff8b813"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.11/dist-packages (4.50.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]) (0.5.3)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]) (0.2.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]) (5.29.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.3.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sacremoses"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLK1p3Km6Xf2",
        "outputId": "1b9c1069-4105-425d-e991-56227b0451c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.11/dist-packages (0.1.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacremoses) (2024.11.6)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from sacremoses) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from sacremoses) (1.4.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sacremoses) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importing Required Libraries**"
      ],
      "metadata": {
        "id": "bjaFHpvflwnQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Required Libraries\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "Ys1_VHlQ6_xg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModel"
      ],
      "metadata": {
        "id": "3opbi6KS6_u8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. SENTIMENT ANALYSIS**"
      ],
      "metadata": {
        "id": "SN7zwlaN_eWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load text classification pipeline from pipeline() using \"sentiment-analysis\" task identifier.\n",
        "# use the default, \"distilbert-base-uncased-finetuned-sst-2-english\" model for sentiment analysis.\n",
        "# input sentence (e.g: random product review) into selected classifier\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "classifier(\"Having three long haired, heavy shedding dogs at home, I was pretty skeptical that this could hold up to all the hair and dirt they trek in, but this wonderful piece of tech has been nothing short of a godsend for me! \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhmTohPt6_sN",
        "outputId": "6941ef2b-f372-44e6-fa01-aa679a8462a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9982457160949707}]"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# result : the sentiment is classified as POSITIVE with 99.8% accuracy score"
      ],
      "metadata": {
        "id": "cp7lgNOi-4jN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Exercise 1 :**\n",
        "\n",
        "> 1. use \"cardiffnlp/twitter-roberta-base-sentiment\" model pre-trained on tweets data, to analyze any tweet of choice. (**NOTE** : output labels for this model are: 0 -> Negative; 1 -> Neutral; 2 -> Positive.)\n",
        "\n",
        "> 2. use the default model (used in Example 1) on the same tweet, to see if the result will change.\n",
        "\n"
      ],
      "metadata": {
        "id": "22j0ovpVAE3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
        "classifier(\"This drinks sucks. We’ve spent hundreds of dollars at many locations and we weren’t allowed to use the restroom without buying something.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGGb8k71-sI0",
        "outputId": "1be32ef7-3f5c-47fc-fa13-4f0d7dfae777"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'LABEL_0', 'score': 0.9493259787559509}]"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "classifier(\"This drinks sucks. We’ve spent hundreds of dollars at many locations and we weren’t allowed to use the restroom without buying something.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-V2xAQRANDY",
        "outputId": "91e24a67-21d1-4eeb-fd7a-10c9be179d8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'NEGATIVE', 'score': 0.9933196306228638}]"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. TOPIC CLASSIFICATION**"
      ],
      "metadata": {
        "id": "FXrxZQioDzSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load a pipeline with \"zero-shot-classification\"\n",
        "# pass a sequence that want to classify and a list of candidate labels.\n",
        "\n",
        "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
        "classifier(\n",
        "    \"Exploratory Data Analysis is the first course in Machine Learning Program that introduces learners to the broad range of Machine Learning concepts, applications, challenges, and solutions, while utilizing interesting real-life datasets\",\n",
        "    candidate_labels=[\"art\", \"natural science\", \"data analysis\"],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAcUIVbLD7aO",
        "outputId": "15132787-3e4c-4c93-e0f0-cf98170d6209"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sequence': 'Exploratory Data Analysis is the first course in Machine Learning Program that introduces learners to the broad range of Machine Learning concepts, applications, challenges, and solutions, while utilizing interesting real-life datasets',\n",
              " 'labels': ['data analysis', 'art', 'natural science'],\n",
              " 'scores': [0.995779275894165, 0.0026982570998370647, 0.0015224807430058718]}"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# result\n",
        "\n",
        "# the model assign corresponding labels to the input.\n",
        "# 'data analysis' is the most successful candidate for the topic of this input, having 99.6% score"
      ],
      "metadata": {
        "id": "Wjio2gp7FyDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Exercise 2 :**\n",
        "\n",
        "> use any sentence of choice to classify it under any classes/ topics of choice. Use \"zero-shot-classification\" and specify the model=\"facebook/bart-large-mnli\".\n",
        "\n"
      ],
      "metadata": {
        "id": "2MnynOVjE3_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
        "classifier(\n",
        "    \"The bond that links your true family is not one of blood, but of respect and joy in each other's life.\",\n",
        "    candidate_labels=[\"life\", \"family\", \"sunset\"],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEfzpX2OE2TB",
        "outputId": "e2cf616c-7cc0-44e9-d75f-64aa19dfc334"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sequence': \"The bond that links your true family is not one of blood, but of respect and joy in each other's life.\",\n",
              " 'labels': ['family', 'life', 'sunset'],\n",
              " 'scores': [0.8444904685020447, 0.10644853115081787, 0.04906097799539566]}"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. TEXT GENERATION MODELS**"
      ],
      "metadata": {
        "id": "8BAHU0MgG8Ui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  load a pipeline with the default \"text-generation\" model, \"gpt2\"\n",
        "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
        "generator(\"This course will teach you\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vUENyNNHEO1",
        "outputId": "b20bc8e0-67d6-492f-ac3e-63117903b67f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'This course will teach you how to understand Google Docs, Google Search, and Google Cloud Calendar. You will also learn how to run Google Apps on Android as well as on iOS for basic troubleshooting. From there, you will learn how to build'}]"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# result : the model continued the \"This course will teach you\" sentence into full sentence"
      ],
      "metadata": {
        "id": "wstuO9mxdLSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Alternative\n",
        "\n",
        "# load a pipeline with \"distilgpt2\" model with parameters, such length and number of the sentences needed\n",
        "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
        "generator(\n",
        "    \"This course will teach you\",\n",
        "    max_length=30,\n",
        "    num_return_sequences=2,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1xFj_8sIAnC",
        "outputId": "f47082b6-45dd-4a2f-ba5f-5f2b185af895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'This course will teach you how to become more agile about building software. This course is free to download via a computer or another program. Free textbooks will'},\n",
              " {'generated_text': 'This course will teach you how long the process will take. We are very excited about the end result here and hope to have you come home the next'}]"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# result : the model gives 2 different sentences, both within 30 words or less, continuing from the sentence \"This course will teach you\"."
      ],
      "metadata": {
        "id": "BrXj-M7vcsmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  4 output options for a 'masked' word in the input sentence\n",
        "unmasker = pipeline(\"fill-mask\", \"distilroberta-base\")\n",
        "unmasker(\"This course will teach you all about <mask> models.\", top_k=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqHF3HMPIz7e",
        "outputId": "41557be3-ec44-4aa1-b000-6a95996bb2b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.19198468327522278,\n",
              "  'token': 30412,\n",
              "  'token_str': ' mathematical',\n",
              "  'sequence': 'This course will teach you all about mathematical models.'},\n",
              " {'score': 0.042092032730579376,\n",
              "  'token': 38163,\n",
              "  'token_str': ' computational',\n",
              "  'sequence': 'This course will teach you all about computational models.'},\n",
              " {'score': 0.03602461889386177,\n",
              "  'token': 27930,\n",
              "  'token_str': ' predictive',\n",
              "  'sequence': 'This course will teach you all about predictive models.'},\n",
              " {'score': 0.02978115901350975,\n",
              "  'token': 745,\n",
              "  'token_str': ' building',\n",
              "  'sequence': 'This course will teach you all about building models.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# result : the model replace the <mask> wih 4 different words"
      ],
      "metadata": {
        "id": "b3wRNvxtea19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> **Exercise 3 :**\n",
        "\n",
        "> use 'text-generator' and 'gpt2' model to complete any sentence. Define any desirable number of returned sentences.\n",
        "\n"
      ],
      "metadata": {
        "id": "fWjBn0dhJyFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# text-generator\n",
        "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
        "generator(\n",
        "    \"Today, the recipe that I will learn is\",\n",
        "    max_length=15,\n",
        "    num_return_sequences=3,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMscwrGjJxci",
        "outputId": "765c28ec-56a3-4d55-a9c6-951365039994"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'Today, the recipe that I will learn is \"Echo\" from the'},\n",
              " {'generated_text': \"Today, the recipe that I will learn is that I'm going to be\"},\n",
              " {'generated_text': 'Today, the recipe that I will learn is how to make my own cinnamon'}]"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. NAME ENTITY RECOGNITION**"
      ],
      "metadata": {
        "id": "msleMzQFLwHh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load a pipeline with \"ner\" model\n",
        "# put sentences as input\n",
        "\n",
        "ner = pipeline(\"ner\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\", grouped_entities=True)\n",
        "ner(\"My name is Roberta and I work with IBM Skills Network in Toronto\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_gcu1OgMKUt",
        "outputId": "fd9dfecb-b73e-4cbc-a86e-aba09e1da2d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'PER',\n",
              "  'score': np.float32(0.9993105),\n",
              "  'word': 'Roberta',\n",
              "  'start': 11,\n",
              "  'end': 18},\n",
              " {'entity_group': 'ORG',\n",
              "  'score': np.float32(0.9976597),\n",
              "  'word': 'IBM Skills Network',\n",
              "  'start': 35,\n",
              "  'end': 53},\n",
              " {'entity_group': 'LOC',\n",
              "  'score': np.float32(0.99702173),\n",
              "  'word': 'Toronto',\n",
              "  'start': 57,\n",
              "  'end': 64}]"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# result : the model identifies all entities (PER, ORG, LOC) in the sentence with highest confidence score"
      ],
      "metadata": {
        "id": "eYotdEA-M2jH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del ner"
      ],
      "metadata": {
        "id": "X1H_9jLYM15V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> **Exercise 4** :\n",
        "\n",
        "> use any sentence of choice to extract entities: person, location and organization, using Name Entity Recognition task, specify model as \"Jean-Baptiste/camembert-ner\".\n",
        "\n"
      ],
      "metadata": {
        "id": "WJML90Y3NgBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ner = pipeline(\"ner\", model=\"Jean-Baptiste/camembert-ner\", grouped_entities=True)\n",
        "ner(\"Her name Amelia and she work under Toyota Company near Mount Fuji\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRcCZQY6N3mf",
        "outputId": "adef074c-2299-4f62-aaf6-72a5ade45ae7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'PER',\n",
              "  'score': np.float32(0.9357212),\n",
              "  'word': 'Amelia',\n",
              "  'start': 8,\n",
              "  'end': 15},\n",
              " {'entity_group': 'ORG',\n",
              "  'score': np.float32(0.9905671),\n",
              "  'word': 'Toyota Company',\n",
              "  'start': 34,\n",
              "  'end': 49},\n",
              " {'entity_group': 'LOC',\n",
              "  'score': np.float32(0.9984614),\n",
              "  'word': 'Mount Fuji',\n",
              "  'start': 54,\n",
              "  'end': 65}]"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. QUESTION ANSWERING**"
      ],
      "metadata": {
        "id": "j01cehktPBDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the pipeline() with \"question-answering\" identifier and model\n",
        "# input question and content\n",
        "# apply model to the input\n",
        "\n",
        "qa_model = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
        "question = \"Which name is also used to describe the Amazon rainforest in English?\"\n",
        "context = \"The Amazon rainforest, also known in English as Amazonia or the Amazon Jungle.\"\n",
        "qa_model(question = question, context = context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUV04eiZPP6S",
        "outputId": "a51cb50f-b835-4222-9c0f-dda69d0b9a6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 0.8247056603431702, 'start': 48, 'end': 56, 'answer': 'Amazonia'}"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# result : the correct answer has been extracted with 82% confidence score."
      ],
      "metadata": {
        "id": "2m6asbebQXHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> **Exercise 5 :**\n",
        "\n",
        "> use any sentence and a question of choice to extract some information, using \"distilbert-base-cased-distilled-squad\" model.\n",
        "\n"
      ],
      "metadata": {
        "id": "NOk7V7J6QmLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qa_model = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
        "question = \"What is the capital city of Malaysia?\"\n",
        "context = \"Malaysia[d] is a country in Southeast Asia. A federal constitutional monarchy, it consists of 13 states and three federal territories. Kuala Lumpur is the national capital, the country's largest city, and the seat of the legislative branch of the federal government.\"\n",
        "qa_model(question = question, context = context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0qHdAxgQVjj",
        "outputId": "b4134d74-9783-4d1b-81eb-3fdd4f453ade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 0.9962024688720703,\n",
              " 'start': 135,\n",
              " 'end': 147,\n",
              " 'answer': 'Kuala Lumpur'}"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. TEXT SUMMARIZATION**"
      ],
      "metadata": {
        "id": "9GJF9uz2TMuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the \"summarization\" pipeline with model\n",
        "# input some text that want to be summarize\n",
        "# check the output"
      ],
      "metadata": {
        "id": "4knnzAfuTMUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")\n",
        "summarizer(\n",
        "    \"\"\"\n",
        "Exploratory Data Analysis is the first course in Machine Learning Program that introduces learners to the broad range of Machine Learning concepts, applications, challenges, and solutions, while utilizing interesting real-life datasets. So, what is EDA and why is it important to perform it before we dive into any analysis?\n",
        "EDA is a visual and statistical process that allows us to take a glimpse into the data before the analysis. It lets us test the assumptions that we might have about the data, proving or disproving our prior believes and biases. It lays foundation for the analysis, so our results go along with our expectations. In a way, it’s a quality check for our predictions.\n",
        "As any data scientist would agree, the most challenging part in any data analysis is to obtain a good quality data to work with. Nothing is served to us on a silver plate, data comes in different shapes and formats. It can be structured and unstructured, it may contain errors or be biased, it may have missing fields, it can have different formats than what an untrained eye would perceive. For example, when we import some data, very often it would contain a time stamp. To a human it is understandable format that can interpreted. But to a machine, it is not interpretable, so it needs to be told what that means, the data needs to be transformed into simple numbers first. There are also different date-time conventions depending on a country (i.e., Canadian versus USA), metric versus imperial systems, and many other data features that need to be recognized before we start doing the analysis. Therefore, the first step before performing any analysis – is get really aquatinted with your data!\n",
        "This course will teach you to ‘see’ and to ‘feel’ the data as well as to transform it into analysis-ready format. It is introductory level course, so no prior knowledge is required, and it is a good starting point if you are interested in getting into the world of Machine Learning. The only thing that is needed is some computer with internet, your curiosity and eagerness to learn and to apply acquired knowledge.  If you live in Canada, you might be interested about gasoline prices in different cities or if you are an insurance actuary you need to analyze the financial risks that you will take based on your clients information. Whatever is the case, you will be able to do your own analysis, and confirm or disprove some of the existing information.\n",
        "The course contains videos and reading materials, as well as well as a lot of interactive practice labs that learners can explore and apply the skills learned. It will allow you to use Python language in Jupyter Notebook, a cloud-based skills network environment that is pre-set for you with all available to be downloaded packages and libraries. It will introduce you to the most common visualization libraries such as Pandas, Seaborn, and Matplotlib to demonstrate various EDA techniques with some real-life datasets.\n",
        "\n",
        "\"\"\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fh39MLgnUTQ_",
        "outputId": "b20fe0aa-45a6-4868-8e32-9311de4727c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'summary_text': ' Exploratory Data Analysis is the first course in Machine Learning Program that introduces learners to the broad range of Machine Learning concepts, applications, challenges, and solutions . EDA is a visual and statistical process that allows us to take a glimpse into the data before the analysis . It lays foundation for the analysis so our results go along with our expectations .'}]"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# result : a short summary of the paragraph"
      ],
      "metadata": {
        "id": "8SYfCM40UuPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del summarizer"
      ],
      "metadata": {
        "id": "3kNpzuTdVCf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> **Exercise 6 :**\n",
        "\n",
        "> Use any document/paragraph of choice and summarize it, using \"sshleifer/distilbart-cnn-12-6\" model.\n",
        "\n"
      ],
      "metadata": {
        "id": "qk9K5QteU3tG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")\n",
        "summarizer(\n",
        "    \"\"\"\n",
        "    Mental health can affect a person’s day-to-day life, relationships, and physical health. External factors in people’s lives and relationships can also contribute to their mental well-being.\n",
        "    Looking after one’s mental health can help a person maintain their ability to enjoy life. This involves balancing their activities, responsibilities, and efforts to achieve psychological resilience.\n",
        "    Stress, depression, and anxiety can affect mental health and may disrupt a person’s routine.\n",
        "    Although healthcare professionals often use the term “mental health,” doctors recognize that many mental health conditions have physical roots.\n",
        "    Everyone is at some risk of developing a mental health disorder, regardless of age, sex, income, or ethnicity. In the U.S. and much of the developed world, depression is one of the leading causesTrusted Source of disability.\n",
        "    Social and financial circumstances, adverse childhood experiences, biological factors, and underlying medical conditions can allTrusted Source shape a person’s mental well-being.\n",
        "    Many people with a mental health disorder have more than oneTrusted Source condition at the same time.\n",
        "    It is important to note that mental well-being depends on a balance of factors, and several elements may contribute to the development of a mental health disorder.\n",
        "\n",
        "\"\"\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SR_XcDr3U22B",
        "outputId": "0af143a7-e180-4af1-82a5-fd300b9af762"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'summary_text': \" Everyone is at some risk of developing a mental health disorder, regardless of age, sex, income, or ethnicity . Social and financial circumstances, adverse childhood experiences, biological factors, and underlying medical conditions can all shape a person's mental well-being . Stress, depression, and anxiety can affect mental health and disrupt a person’s routine .\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. TRANSLATION**"
      ],
      "metadata": {
        "id": "LxfyS80sW7Fo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# monolingual"
      ],
      "metadata": {
        "id": "hyapsGRdYQi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add task prefix : \"_en_to_fr\" to translate English to French\n",
        "\n",
        "en_fr_translator = pipeline(\"translation_en_to_fr\", model=\"t5-small\")\n",
        "en_fr_translator(\"How old are you?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RHamoM-XOqp",
        "outputId": "68eb0af9-2a54-42ae-a1bd-1d0ba78701b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'translation_text': 'Quel est votre âge ?'}]"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# result : the sentence translate from English to French"
      ],
      "metadata": {
        "id": "wBiaakrNa0xy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Alternative\n",
        "\n",
        "# load the \"translator\" pipeline\n",
        "# use a specific model that is from one specific language to another (e.g : French-English),\n",
        "# input some text that want to be translated\n",
        "# check the output\n",
        "\n",
        "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-fr-en\")\n",
        "translator(\"La science des données est la meilleure.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HTPyPkRYONu",
        "outputId": "e8d7c287-746d-47bc-91f7-00561aed115d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'translation_text': 'Data science is the best.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> **Exercise 7 :**\n",
        "\n",
        "> Use any sentence of choice to translate English to German. The translation model you can use is \"translation_en_to_de\"\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "v5KI7heCZr4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "en_de_translator = pipeline(\"translation_en_to_de\", model=\"t5-small\")\n",
        "en_de_translator(\"Hello! How are you?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c15N82XtZ4Un",
        "outputId": "8a56a008-03df-4f20-d6ed-270d455208b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'translation_text': 'Hallo, wie sind Sie?'}]"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    }
  ]
}